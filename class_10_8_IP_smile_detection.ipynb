{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ðŸ‘‰ class_10_8 IP Â» _Smile Detection_ </center>  \n",
    "https://www.geeksforgeeks.org/line-detection-python-opencv-houghline-method/?ref=lbp  \n",
    "https://bkshin.tistory.com/entry/OpenCV-20     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emotion detectors are used in many industries, one being the media industry where it is important for the companies to determine the public reaction to their products. In this article, we are going to build a smile detector using OpenCV which takes in live feed from webcam. The smile/happiness detector that we are going to implement would be a raw one, there exist many better ways to implement it.\n",
    "\n",
    "Step #1 : Include the desired haar-cascades.\n",
    "- Haar-cascades are classifiers that are used to detect features (of face in this case) by superimposing predefined patterns over face segments and are used as XML files.   \n",
    "In our model, we shall use face, eye and smile haar-cascades, which after downloading need to be placed in the working directory.\n",
    ">- **face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')**  \n",
    ">- **eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_eye.xml')**  \n",
    ">- **smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_smile.xml')**  \n",
    "\n",
    "The live feed coming from the webcam/video device is processed frame by frame.   \n",
    "We process the gray scale image, as haar-cascades work better on them.\n",
    "To detect the face, we use: \n",
    "\n",
    "**faces  = face_cascade.detectMultiScale(gray, 1.3, 5)**  \n",
    "\n",
    "where 1.3 is the scaling factor, and 5 is the number of nearest neighbors.   \n",
    "We can adjust these factors as per our convenience/results to improve our detector.  \n",
    "Now for each subsequent face detected, we need to check for smiles. \n",
    " \n",
    "    def detect(gray, frame):\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), ((x + w), (y + h)), (255, 0, 0), 2)\n",
    "            roi_gray = gray[y:y + h, x:x + w]\n",
    "            roi_color = frame[y:y + h, x:x + w]\n",
    "            smiles = smile_cascade.detectMultiScale(roi_gray, 1.8, 20)\n",
    "\n",
    "            for (sx, sy, sw, sh) in smiles:\n",
    "                cv2.rectangle(roi_color, (sx, sy), ((sx + sw), (sy + sh)), (0, 0, 255), 2)\n",
    "        return frame  \n",
    "    \n",
    "\n",
    "    Explanations: \n",
    "\n",
    "    - The face data is stored as tuples of coordinates.   \n",
    "    - Here, x and y define the coordinate of the upper-left corner of the face frame,   \n",
    "    - w and h define the width and height of the frame. \n",
    "\n",
    "    - The cv2.rectangle function takes in the arguments frame, upper-left coordinates of the face, lower right coordinates,   \n",
    "    - the RGB code for the rectangle (that would contain within it the detected face) and the thickness of the rectangle. \n",
    "\n",
    "    - The roi_gray defines the region of interest of the face and roi_color does the same for the original frame. \n",
    "\n",
    "    - In line 7, we apply smile detection using the cascade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "def detect(gray, frame):\n",
    "    faces  = smile_cascade.detectMultiScale(gray, 1.3, 5) \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), ((x + w), (y + h)), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = frame[y:y + h, x:x + w]\n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, 1.8, 20)\n",
    "\n",
    "        for (sx, sy, sw, sh) in smiles:\n",
    "            cv2.rectangle(roi_color, (sx, sy), ((sx + sw), (sy + sh)), (0, 0, 255), 2)\n",
    "    return frame  \n",
    "\n",
    "smile_cascade = cv2.CascadeClassifier('./cv_data/haarcascade_smile.xml')\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while video_capture.isOpened():\n",
    "    _, frame = video_capture.read()  # Captures video_capture frame by frame\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)   # To capture image in monochrome \n",
    "    canvas = detect(gray, frame)    # calls the detect() function  \n",
    "    \n",
    "    cv2.imshow('Video', canvas) \n",
    "  \n",
    "    # The control breaks once q key is pressed                        \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):               \n",
    "        break\n",
    "\n",
    "video_capture.release()                                 \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7_YOLO",
   "language": "python",
   "name": "yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
