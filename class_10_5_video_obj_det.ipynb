{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> 👉 class_10_5 » _Object Tracking - Meanshift and Camshift_ </center>\n",
    "\n",
    "OpenCV is the huge open-source library for computer vision, machine learning, and image processing and now it plays a major role in real-time operation which is very important in today's systems.   \n",
    "By using it, one can process images and videos to identify objects, faces, or even the handwriting of a human. \n",
    "\n",
    "        OpenCV는 컴퓨터 비전, 기계 학습 및 이미지 처리를 위한 거대한 오픈 소스 라이브러리이며 이제 오늘날 시스템에서 매우 중요한 실시간 작동에서 중요한 역할을 합니다.   \n",
    "        이를 사용하면 이미지와 비디오를 처리하여 물체, 얼굴 또는 사람의 필체를 식별할 수 있습니다. \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Dense Optical Flow:** These algorithms help estimate the motion vector of every pixel in a video frame.\n",
    "* **Sparse Optical Flow:** These algorithms, like the Kanade-Lucas-Tomashi (KLT) feature tracker, track the location of a few feature points in an image.\n",
    "* **Kalman Filtering:** A very popular signal processing algorithm used to predict the location of a moving object based on prior motion information.   \n",
    ">- One of the early applications of this algorithm was missile guidance!   \n",
    ">- Also \"the on-board computer that guided the descent of the Apollo 11 lunar module to the moon had a Kalman filter\".  \n",
    "* **Meanshift and Camshift:** These are algorithms for locating the maxima of a density function. They are also used for tracking.\n",
    "* **Single Object Trackers:** In this class of trackers, the first frame is marked using a rectangle to indicate the location of the object we want to track.   \n",
    "The object is then tracked in subsequent frames using the tracking algorithm.   \n",
    "In most real-life applications, these trackers are used in conjunction with an object detector.\n",
    "* **Multiple Object Track finding algorithms:** In cases when we have a fast object detector, it makes sense to detect multiple objects in each frame and then run a track finding algorithm that identifies which rectangle in one frame corresponds to a rectangle in the next frame.\n",
    ">- Multiple Object Tracking has come a long way.   \n",
    ">- It uses object detection and novel motion prediction algorithms to get accurate tracking information.   \n",
    ">- For example, DeepSort uses the YOLO network to get blazing-fast inference speed. It is based on SORT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▣ Meanshift and Camshift\n",
    "\n",
    "## ▶ Meanshift \n",
    "\n",
    "The basic idea behind Meanshift is that every instance of a video is determined by the form of the pixel distribution of that frame.   \n",
    "We define an initial window, generally a square or a circle for which the positions are specified by ourself which identifies the area of maximum pixel distribution   \n",
    "and tries to keep track of that area in the video so that when the video is running our tracking window also moves towards the region of maximum pixel distribution.   \n",
    "The direction of movement depends upon the difference between the center of our tracking window and the centroid of all the k-pixels inside that window.\n",
    "Meanshift is __a very useful method to keep track of a particular object inside a video.__   \n",
    "Meanshift can __separate the static background of a video and the moving foreground object.__\n",
    "\n",
    "        Meanshift의 기본 아이디어는 비디오의 모든 인스턴스가 해당 프레임의 픽셀 분포 형태로 확인된다는 것입니다.\n",
    "        우리는 초기 창(일반적으로 최대 픽셀 분포 영역을 식별하는 위치가 스스로 지정되는 정사각형 또는 원)을 정의합니다.\n",
    "        그리고 비디오가 실행 중일 때 추적 창도 최대 픽셀 분포 영역을 향해 이동하도록 비디오에서 해당 영역을 추적하려고 합니다.\n",
    "        이동 방향은 추적 창 중심과 해당 창 내부의 모든 k-픽셀 중심 간의 차이에 따라 달라집니다.\n",
    "        Meanshift는 비디오 내의 특정 개체를 추적하는 데 매우 유용한 방법입니다.\n",
    "        Meanshift는 비디오의 정적 배경과 움직이는 전경 개체를 분리할 수 있습니다.  \n",
    "\n",
    "        \n",
    "To use meanshift in OpenCV, first we need to setup the target, find its histogram so that we can backproject the target on each frame for calculation of meanshift.   \n",
    "We also need to provide an initial location of window.   \n",
    "For histogram, only Hue is considered here.   \n",
    "Also, to avoid false values due to low light, low light values are discarded using cv.inRange() function.         \n",
    "\n",
    "        OpenCV에서 평균 이동을 사용하려면 먼저 목표를 설정하고 평균 이동 계산을 위해 각 프레임의 목표를 역투영할 수 있도록 히스토그램을 찾아야 합니다.\n",
    "        또한 창의 초기 위치도 제공해야 합니다.\n",
    "        히스토그램의 경우 여기서는 Hue만 고려됩니다.\n",
    "        또한 낮은 조명으로 인한 잘못된 값을 방지하기 위해 cv.inRange() 함수를 사용하여 낮은 조명 값을 삭제합니다.  \n",
    "        \n",
    "Examples: \n",
    "\n",
    "1. The tracking windows is tracking the football and the football player. \n",
    "\n",
    "<img src='./images/practice_img/obj0.png' align='left' width=400 height=400><img src='./images/practice_img/obj1.png'  width=400 height=400> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Disadvantages of using meanshift  \n",
    "\n",
    "There are 2 main disadvantages of using the Meanshift for object tracking.  \n",
    "\n",
    "- The size of the tracking window remains the same irrespective of the distance of the object from the camera.  \n",
    "- The Window will track the object only when it is in the region of that object.  \n",
    "- So we must hardcode our position of the window carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select Area for meanShift and Enter a Key\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "col, width, row, height = -1,-1,-1,-1        # set initial value\n",
    "frame = None                                 # video output\n",
    "frame2 = None                                # org img\n",
    "inputmode = False                            # roi\n",
    "rectangle = False\n",
    "trackWindow = None\n",
    "roi_hist = None\n",
    "\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    global col, width, row, height, frame, frame2, inputmode\n",
    "    global rectangle, roi_hist, trackWindow\n",
    "\n",
    "    if inputmode:                          # press sapce bar   \n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            rectangle = True \n",
    "            col, row = x,y\n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if rectangle:\n",
    "                frame = frame2.copy() \n",
    "                cv2.rectangle(frame,(col, row), (x,y),(0,255,0),2)  \n",
    "                cv2.imshow('frame',frame)\n",
    "        elif event == cv2.EVENT_LBUTTONUP:  \n",
    "            inputmode = False\n",
    "            rectangle = False \n",
    "            cv2.rectangle(frame,(col,row),(x,y),(0,255,0),2) \n",
    "            height, width = abs(row-y),abs(col-x) \n",
    "            trackWindow = (col, row, width, height) \n",
    "            roi = frame[row:row+height, col:col+width] \n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV) \n",
    "            roi_hist = cv2.calcHist([roi],[0], None, [180],[0,180]) # 2D img histo, Hue value 0~179\n",
    "            cv2.normalize(roi_hist, roi_hist, 0 , 255, cv2.NORM_MINMAX) # 0~179 => 0~255 \n",
    "    return\n",
    "\n",
    "def meanShift(file):\n",
    "    global frame, frame2, inputmode, trackWindow, roi_hist\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(file)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "    ret, frame = cap.read() \n",
    "    cv2.namedWindow('frame')\n",
    "    cv2.setMouseCallback('frame',onMouse,param=(frame,frame2)) \n",
    "    termination = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) # meanShift\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if trackWindow is not None: \n",
    "            hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "            dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1) \n",
    "            cv2.imshow('dst',dst)\n",
    "            ret, trackWindow = cv2.meanShift(dst, trackWindow, termination) \n",
    "            x,y,w,h = trackWindow \n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h), (0,255,0),2)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(55)\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        if k == ord(' '): # space bar press\n",
    "            print(\"select Area for meanShift and Enter a Key\")\n",
    "            inputmode = True\n",
    "            frame2 = frame.copy() \n",
    "\n",
    "            while inputmode:\n",
    "                cv2.imshow('frame',frame)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "meanShift('./Videos/boy-walking.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ Camshift  \n",
    "\n",
    "Our window always has the same size whether the car is very far or very close to the camera.   \n",
    "That is not good. We need to adapt the window size with size and rotation of the target.   \n",
    "The solution came from \"OpenCV Labs\" and it is called CAMshift (Continuously Adaptive Meanshift) published by Gary Bradsky in his paper \"Computer Vision Face Tracking for Use in a Perceptual User Interface\" in 1998 [33] .\n",
    "CAMshift tries to tackle the scale problem by using varying window size for applying meanshift.   \n",
    "- Steps 1 and 2 are the same as that of MeanShift.   \n",
    "- In the third step, we find the backproject image and then use CamShift() openCV function to track the position of the object in the new frame.   \n",
    "- This function finds the an object center using meanshift and then adjust the window size.   \n",
    "- This funciton returns the rotaed rectangle that includes the object position, size, and orientation.  \n",
    "\n",
    "It applies meanshift first. Once meanshift converges, it updates the size of the window as, s=2×M00256−−−√. It also calculates the orientation of the best fitting ellipse to it.   \n",
    "Again it applies the meanshift with new scaled search window and previous window location.   \n",
    "The process continues until the required accuracy is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select Area for CamShift and Enter a Key\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "col, width, row, height = -1,-1,-1,-1\n",
    "frame = None\n",
    "frame2 = None\n",
    "inputmode = False\n",
    "rectangle = False\n",
    "trackWindow = None\n",
    "roi_hist = None\n",
    "\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    global col, width, row, height, frame, frame2, inputmode\n",
    "    global rectangle, roi_hist, trackWindow\n",
    "    if inputmode:\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            rectangle = True\n",
    "            col, row = x,y\n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if rectangle:\n",
    "                frame = frame2.copy()\n",
    "                cv2.rectangle(frame,(col, row), (x,y),(0,255,0),2)\n",
    "                cv2.imshow('frame',frame)\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            inputmode = False\n",
    "            rectangle = False\n",
    "            cv2.rectangle(frame,(col,row),(x,y),(0,255,0),2)\n",
    "            height, width = abs(row-y),abs(col-x)\n",
    "            trackWindow = (col, row, width, height)\n",
    "            roi = frame[row:row+height, col:col+width]\n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "            roi_hist = cv2.calcHist([roi],[0], None, [180],[0,180])\n",
    "            cv2.normalize(roi_hist, roi_hist, 0 , 255, cv2.NORM_MINMAX) \n",
    "    return\n",
    "\n",
    "def CamShift(file):\n",
    "    global frame, frame2, inputmode, trackWindow, roi_hist\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(file)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "    ret, frame = cap.read()\n",
    "    cv2.namedWindow('frame')\n",
    "    cv2.setMouseCallback('frame',onMouse,param=(frame,frame2))\n",
    "    termination = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if trackWindow is not None:\n",
    "            hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "            dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "            cv2.imshow('dst',dst)\n",
    "            ret, trackWindow = cv2.CamShift(dst, trackWindow, termination) \n",
    "            pts = cv2.boxPoints(ret) \n",
    "            pts = np.int0(pts) \n",
    "            cv2.polylines(frame,[pts],True,(0,255,0),2) \n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(55)\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        if k == ord(' '):\n",
    "            print(\"select Area for CamShift and Enter a Key\")\n",
    "            inputmode = True\n",
    "            frame2 = frame.copy() \n",
    "            \n",
    "            while inputmode:\n",
    "                cv2.imshow('frame',frame)\n",
    "                cv2.waitKey(0)\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "CamShift('./Videos/boy-walking.mp4')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ MeanShift Face Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MeanShift Face Track\n",
    "# https://github.com/prabormukherjee/Object_tracking-opencv/blob/master/03_MeanShift_Tracking.ipynb\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture('./Videos/face_track.mp4') # face_track.mp4   chaplin.mp4\n",
    "ret, frame = cap.read()\n",
    "face_casc = cv2.CascadeClassifier('./cv_data/haarcascade_frontalface_default.xml')\n",
    "face_rects = face_casc.detectMultiScale(frame)\n",
    "face_x, face_y, w,h = tuple(face_rects[0]) # Convert the list to a tuple\n",
    "track_window = (face_x, face_y, w, h)\n",
    "roi = frame[face_y: face_y+h, face_x: face_x+w]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0,180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX);\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) # Set the termination criteria 10 iterations or move 1 pt\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dest = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        ret, track_window = cv2.meanShift(dest, track_window, term_crit)\n",
    "        x, y, w, h = track_window\n",
    "        img2 = cv2.rectangle(frame, (x, y),(x+w, y+h),(255, 255, 0))\n",
    "        cv2.imshow('Face Tracker', img2)\n",
    "\n",
    "        if cv2.waitKey(300) & 0xFF == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ▶ CamShift Face Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture('Videos/face_track.mp4')\n",
    "ret, frame = cap.read()\n",
    "face_casc = cv2.CascadeClassifier('./cv_data/haarcascade_frontalface_default.xml')\n",
    "face_rects = face_casc.detectMultiScale(frame)\n",
    "face_x, face_y, w,h = tuple(face_rects[0])\n",
    "track_window = (face_x, face_y, w, h)\n",
    "roi = frame[face_y: face_y+h,face_x: face_x+w]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0,180]) # Histogram to target on each frame for the meanshift calculation\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX);  # Normalize the histogram\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) # Set the termination criteria 10 iterations or move 1 pt\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dest = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        ret, track_window = cv2.CamShift(dest, track_window, term_crit) # Camshift to get the new coordinates of rectangle\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        img2 = cv2.polylines(frame, [pts], True, (0, 255, 0), 5)\n",
    "        cv2.imshow('Cam Shift', img2)\n",
    "        \n",
    "        if cv2.waitKey(300) & 0xFF == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV-py36",
   "language": "python",
   "name": "cv_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
