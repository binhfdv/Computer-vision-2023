{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ğŸ‘‰ class_10_5 Â» _Object Tracking - Meanshift and Camshift_ </center>\n",
    "\n",
    "OpenCV is the huge open-source library for computer vision, machine learning, and image processing and now it plays a major role in real-time operation which is very important in today's systems.   \n",
    "By using it, one can process images and videos to identify objects, faces, or even the handwriting of a human. \n",
    "\n",
    "        OpenCVëŠ” ì»´í“¨í„° ë¹„ì „, ê¸°ê³„ í•™ìŠµ ë° ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ê±°ëŒ€í•œ ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë©° ì´ì œ ì˜¤ëŠ˜ë‚  ì‹œìŠ¤í…œì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ì‹¤ì‹œê°„ ì‘ë™ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.   \n",
    "        ì´ë¥¼ ì‚¬ìš©í•˜ë©´ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë¬¼ì²´, ì–¼êµ´ ë˜ëŠ” ì‚¬ëŒì˜ í•„ì²´ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Dense Optical Flow:** These algorithms help estimate the motion vector of every pixel in a video frame.\n",
    "* **Sparse Optical Flow:** These algorithms, like the Kanade-Lucas-Tomashi (KLT) feature tracker, track the location of a few feature points in an image.\n",
    "* **Kalman Filtering:** A very popular signal processing algorithm used to predict the location of a moving object based on prior motion information.   \n",
    ">- One of the early applications of this algorithm was missile guidance!   \n",
    ">- Also \"the on-board computer that guided the descent of the Apollo 11 lunar module to the moon had a Kalman filter\".  \n",
    "* **Meanshift and Camshift:** These are algorithms for locating the maxima of a density function. They are also used for tracking.\n",
    "* **Single Object Trackers:** In this class of trackers, the first frame is marked using a rectangle to indicate the location of the object we want to track.   \n",
    "The object is then tracked in subsequent frames using the tracking algorithm.   \n",
    "In most real-life applications, these trackers are used in conjunction with an object detector.\n",
    "* **Multiple Object Track finding algorithms:** In cases when we have a fast object detector, it makes sense to detect multiple objects in each frame and then run a track finding algorithm that identifies which rectangle in one frame corresponds to a rectangle in the next frame.\n",
    ">- Multiple Object Tracking has come a long way.   \n",
    ">- It uses object detection and novel motion prediction algorithms to get accurate tracking information.   \n",
    ">- For example, DeepSort uses the YOLO network to get blazing-fast inference speed. It is based on SORT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–£ Meanshift and Camshift\n",
    "\n",
    "## â–¶ Meanshift \n",
    "\n",
    "The basic idea behind Meanshift is that every instance of a video is determined by the form of the pixel distribution of that frame.   \n",
    "We define an initial window, generally a square or a circle for which the positions are specified by ourself which identifies the area of maximum pixel distribution   \n",
    "and tries to keep track of that area in the video so that when the video is running our tracking window also moves towards the region of maximum pixel distribution.   \n",
    "The direction of movement depends upon the difference between the center of our tracking window and the centroid of all the k-pixels inside that window.\n",
    "Meanshift is __a very useful method to keep track of a particular object inside a video.__   \n",
    "Meanshift can __separate the static background of a video and the moving foreground object.__\n",
    "\n",
    "        Meanshiftì˜ ê¸°ë³¸ ì•„ì´ë””ì–´ëŠ” ë¹„ë””ì˜¤ì˜ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ê°€ í•´ë‹¹ í”„ë ˆì„ì˜ í”½ì…€ ë¶„í¬ í˜•íƒœë¡œ í™•ì¸ëœë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "        ìš°ë¦¬ëŠ” ì´ˆê¸° ì°½(ì¼ë°˜ì ìœ¼ë¡œ ìµœëŒ€ í”½ì…€ ë¶„í¬ ì˜ì—­ì„ ì‹ë³„í•˜ëŠ” ìœ„ì¹˜ê°€ ìŠ¤ìŠ¤ë¡œ ì§€ì •ë˜ëŠ” ì •ì‚¬ê°í˜• ë˜ëŠ” ì›)ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "        ê·¸ë¦¬ê³  ë¹„ë””ì˜¤ê°€ ì‹¤í–‰ ì¤‘ì¼ ë•Œ ì¶”ì  ì°½ë„ ìµœëŒ€ í”½ì…€ ë¶„í¬ ì˜ì—­ì„ í–¥í•´ ì´ë™í•˜ë„ë¡ ë¹„ë””ì˜¤ì—ì„œ í•´ë‹¹ ì˜ì—­ì„ ì¶”ì í•˜ë ¤ê³  í•©ë‹ˆë‹¤.\n",
    "        ì´ë™ ë°©í–¥ì€ ì¶”ì  ì°½ ì¤‘ì‹¬ê³¼ í•´ë‹¹ ì°½ ë‚´ë¶€ì˜ ëª¨ë“  k-í”½ì…€ ì¤‘ì‹¬ ê°„ì˜ ì°¨ì´ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\n",
    "        MeanshiftëŠ” ë¹„ë””ì˜¤ ë‚´ì˜ íŠ¹ì • ê°œì²´ë¥¼ ì¶”ì í•˜ëŠ” ë° ë§¤ìš° ìœ ìš©í•œ ë°©ë²•ì…ë‹ˆë‹¤.\n",
    "        MeanshiftëŠ” ë¹„ë””ì˜¤ì˜ ì •ì  ë°°ê²½ê³¼ ì›€ì§ì´ëŠ” ì „ê²½ ê°œì²´ë¥¼ ë¶„ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "\n",
    "        \n",
    "To use meanshift in OpenCV, first we need to setup the target, find its histogram so that we can backproject the target on each frame for calculation of meanshift.   \n",
    "We also need to provide an initial location of window.   \n",
    "For histogram, only Hue is considered here.   \n",
    "Also, to avoid false values due to low light, low light values are discarded using cv.inRange() function.         \n",
    "\n",
    "        OpenCVì—ì„œ í‰ê·  ì´ë™ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¨¼ì € ëª©í‘œë¥¼ ì„¤ì •í•˜ê³  í‰ê·  ì´ë™ ê³„ì‚°ì„ ìœ„í•´ ê° í”„ë ˆì„ì˜ ëª©í‘œë¥¼ ì—­íˆ¬ì˜í•  ìˆ˜ ìˆë„ë¡ íˆìŠ¤í† ê·¸ë¨ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.\n",
    "        ë˜í•œ ì°½ì˜ ì´ˆê¸° ìœ„ì¹˜ë„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "        íˆìŠ¤í† ê·¸ë¨ì˜ ê²½ìš° ì—¬ê¸°ì„œëŠ” Hueë§Œ ê³ ë ¤ë©ë‹ˆë‹¤.\n",
    "        ë˜í•œ ë‚®ì€ ì¡°ëª…ìœ¼ë¡œ ì¸í•œ ì˜ëª»ëœ ê°’ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ cv.inRange() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚®ì€ ì¡°ëª… ê°’ì„ ì‚­ì œí•©ë‹ˆë‹¤.  \n",
    "        \n",
    "Examples: \n",
    "\n",
    "1. The tracking windows is tracking the football and the football player. \n",
    "\n",
    "<img src='./images/practice_img/obj0.png' align='left' width=400 height=400><img src='./images/practice_img/obj1.png'  width=400 height=400> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â–  Disadvantages of using meanshift  \n",
    "\n",
    "There are 2 main disadvantages of using the Meanshift for object tracking.  \n",
    "\n",
    "- The size of the tracking window remains the same irrespective of the distance of the object from the camera.  \n",
    "- The Window will track the object only when it is in the region of that object.  \n",
    "- So we must hardcode our position of the window carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select Area for meanShift and Enter a Key\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "col, width, row, height = -1,-1,-1,-1        # set initial value\n",
    "frame = None                                 # video output\n",
    "frame2 = None                                # org img\n",
    "inputmode = False                            # roi\n",
    "rectangle = False\n",
    "trackWindow = None\n",
    "roi_hist = None\n",
    "\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    global col, width, row, height, frame, frame2, inputmode\n",
    "    global rectangle, roi_hist, trackWindow\n",
    "\n",
    "    if inputmode:                          # press sapce bar   \n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            rectangle = True \n",
    "            col, row = x,y\n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if rectangle:\n",
    "                frame = frame2.copy() \n",
    "                cv2.rectangle(frame,(col, row), (x,y),(0,255,0),2)  \n",
    "                cv2.imshow('frame',frame)\n",
    "        elif event == cv2.EVENT_LBUTTONUP:  \n",
    "            inputmode = False\n",
    "            rectangle = False \n",
    "            cv2.rectangle(frame,(col,row),(x,y),(0,255,0),2) \n",
    "            height, width = abs(row-y),abs(col-x) \n",
    "            trackWindow = (col, row, width, height) \n",
    "            roi = frame[row:row+height, col:col+width] \n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV) \n",
    "            roi_hist = cv2.calcHist([roi],[0], None, [180],[0,180]) # 2D img histo, Hue value 0~179\n",
    "            cv2.normalize(roi_hist, roi_hist, 0 , 255, cv2.NORM_MINMAX) # 0~179 => 0~255 \n",
    "    return\n",
    "\n",
    "def meanShift(file):\n",
    "    global frame, frame2, inputmode, trackWindow, roi_hist\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(file)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "    ret, frame = cap.read() \n",
    "    cv2.namedWindow('frame')\n",
    "    cv2.setMouseCallback('frame',onMouse,param=(frame,frame2)) \n",
    "    termination = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) # meanShift\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if trackWindow is not None: \n",
    "            hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "            dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1) \n",
    "            cv2.imshow('dst',dst)\n",
    "            ret, trackWindow = cv2.meanShift(dst, trackWindow, termination) \n",
    "            x,y,w,h = trackWindow \n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h), (0,255,0),2)\n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(55)\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        if k == ord(' '): # space bar press\n",
    "            print(\"select Area for meanShift and Enter a Key\")\n",
    "            inputmode = True\n",
    "            frame2 = frame.copy() \n",
    "\n",
    "            while inputmode:\n",
    "                cv2.imshow('frame',frame)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "meanShift('./Videos/boy-walking.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ Camshift  \n",
    "\n",
    "Our window always has the same size whether the car is very far or very close to the camera.   \n",
    "That is not good. We need to adapt the window size with size and rotation of the target.   \n",
    "The solution came from \"OpenCV Labs\" and it is called CAMshift (Continuously Adaptive Meanshift) published by Gary Bradsky in his paper \"Computer Vision Face Tracking for Use in a Perceptual User Interface\" in 1998 [33] .\n",
    "CAMshift tries to tackle the scale problem by using varying window size for applying meanshift.   \n",
    "- Steps 1 and 2 are the same as that of MeanShift.   \n",
    "- In the third step, we find the backproject image and then use CamShift() openCV function to track the position of the object in the new frame.   \n",
    "- This function finds the an object center using meanshift and then adjust the window size.   \n",
    "- This funciton returns the rotaed rectangle that includes the object position, size, and orientation.  \n",
    "\n",
    "It applies meanshift first. Once meanshift converges, it updates the size of the window as, s=2Ã—M00256âˆ’âˆ’âˆ’âˆš. It also calculates the orientation of the best fitting ellipse to it.   \n",
    "Again it applies the meanshift with new scaled search window and previous window location.   \n",
    "The process continues until the required accuracy is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select Area for CamShift and Enter a Key\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "col, width, row, height = -1,-1,-1,-1\n",
    "frame = None\n",
    "frame2 = None\n",
    "inputmode = False\n",
    "rectangle = False\n",
    "trackWindow = None\n",
    "roi_hist = None\n",
    "\n",
    "def onMouse(event, x, y, flags, param):\n",
    "    global col, width, row, height, frame, frame2, inputmode\n",
    "    global rectangle, roi_hist, trackWindow\n",
    "    if inputmode:\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            rectangle = True\n",
    "            col, row = x,y\n",
    "        elif event == cv2.EVENT_MOUSEMOVE:\n",
    "            if rectangle:\n",
    "                frame = frame2.copy()\n",
    "                cv2.rectangle(frame,(col, row), (x,y),(0,255,0),2)\n",
    "                cv2.imshow('frame',frame)\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            inputmode = False\n",
    "            rectangle = False\n",
    "            cv2.rectangle(frame,(col,row),(x,y),(0,255,0),2)\n",
    "            height, width = abs(row-y),abs(col-x)\n",
    "            trackWindow = (col, row, width, height)\n",
    "            roi = frame[row:row+height, col:col+width]\n",
    "            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "            roi_hist = cv2.calcHist([roi],[0], None, [180],[0,180])\n",
    "            cv2.normalize(roi_hist, roi_hist, 0 , 255, cv2.NORM_MINMAX) \n",
    "    return\n",
    "\n",
    "def CamShift(file):\n",
    "    global frame, frame2, inputmode, trackWindow, roi_hist\n",
    "    try:\n",
    "        cap = cv2.VideoCapture(file)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return\n",
    "    ret, frame = cap.read()\n",
    "    cv2.namedWindow('frame')\n",
    "    cv2.setMouseCallback('frame',onMouse,param=(frame,frame2))\n",
    "    termination = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if trackWindow is not None:\n",
    "            hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "            dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "            cv2.imshow('dst',dst)\n",
    "            ret, trackWindow = cv2.CamShift(dst, trackWindow, termination) \n",
    "            pts = cv2.boxPoints(ret) \n",
    "            pts = np.int0(pts) \n",
    "            cv2.polylines(frame,[pts],True,(0,255,0),2) \n",
    "\n",
    "        cv2.imshow('frame',frame)\n",
    "        k = cv2.waitKey(55)\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        if k == ord(' '):\n",
    "            print(\"select Area for CamShift and Enter a Key\")\n",
    "            inputmode = True\n",
    "            frame2 = frame.copy() \n",
    "            \n",
    "            while inputmode:\n",
    "                cv2.imshow('frame',frame)\n",
    "                cv2.waitKey(0)\n",
    "                \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "CamShift('./Videos/boy-walking.mp4')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ MeanShift Face Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MeanShift Face Track\n",
    "# https://github.com/prabormukherjee/Object_tracking-opencv/blob/master/03_MeanShift_Tracking.ipynb\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture('./Videos/face_track.mp4') # face_track.mp4   chaplin.mp4\n",
    "ret, frame = cap.read()\n",
    "face_casc = cv2.CascadeClassifier('./cv_data/haarcascade_frontalface_default.xml')\n",
    "face_rects = face_casc.detectMultiScale(frame)\n",
    "face_x, face_y, w,h = tuple(face_rects[0]) # Convert the list to a tuple\n",
    "track_window = (face_x, face_y, w, h)\n",
    "roi = frame[face_y: face_y+h, face_x: face_x+w]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0,180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX);\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) # Set the termination criteria 10 iterations or move 1 pt\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dest = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        ret, track_window = cv2.meanShift(dest, track_window, term_crit)\n",
    "        x, y, w, h = track_window\n",
    "        img2 = cv2.rectangle(frame, (x, y),(x+w, y+h),(255, 255, 0))\n",
    "        cv2.imshow('Face Tracker', img2)\n",
    "\n",
    "        if cv2.waitKey(300) & 0xFF == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ CamShift Face Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture('Videos/face_track.mp4')\n",
    "ret, frame = cap.read()\n",
    "face_casc = cv2.CascadeClassifier('./cv_data/haarcascade_frontalface_default.xml')\n",
    "face_rects = face_casc.detectMultiScale(frame)\n",
    "face_x, face_y, w,h = tuple(face_rects[0])\n",
    "track_window = (face_x, face_y, w, h)\n",
    "roi = frame[face_y: face_y+h,face_x: face_x+w]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0,180]) # Histogram to target on each frame for the meanshift calculation\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX);  # Normalize the histogram\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1) # Set the termination criteria 10 iterations or move 1 pt\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dest = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        ret, track_window = cv2.CamShift(dest, track_window, term_crit) # Camshift to get the new coordinates of rectangle\n",
    "        pts = cv2.boxPoints(ret)\n",
    "        pts = np.int0(pts)\n",
    "        img2 = cv2.polylines(frame, [pts], True, (0, 255, 0), 5)\n",
    "        cv2.imshow('Cam Shift', img2)\n",
    "        \n",
    "        if cv2.waitKey(300) & 0xFF == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV-py36",
   "language": "python",
   "name": "cv_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
