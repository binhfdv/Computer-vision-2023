{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> ðŸ‘‰ class_10_1 Video Â» _Realtime Canny Edge, Road Lane Detection_ </center>\n",
    "\n",
    "## Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np  \n",
    "  \n",
    "cap = cv2.VideoCapture(0)  \n",
    "  \n",
    "while (1):  \n",
    "  \n",
    "    ret, frame = cap.read()  \n",
    "    cv2.imshow('Original', frame)  \n",
    "    edges = cv2.Canny(frame, 100, 200,True)  \n",
    "    cv2.imshow('Edges', edges)  \n",
    "  \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Road Lane Detection\n",
    "\n",
    "### Steps in Road Lane Detection  \n",
    "\n",
    "1. Capturing and decoding video file: \n",
    ">- We will capture the video using VideoFileClip object and after the capturing has been initialized every video frame is decoded (i.e. converting into a sequence of images).\n",
    "2. Grayscale conversion of image: \n",
    ">- The video frames are in RGB format, RGB is converted to grayscale because processing a single channel image is faster than processing a three-channel colored image.\n",
    "3. Reduce noise: \n",
    ">- Noise can create false edges, therefore before going further, itâ€™s imperative to perform image smoothening.   \n",
    ">- Gaussian blur is used to perform this process. Gaussian blur is a typical image filtering technique for lowering noise and enhancing image characteristics.   \n",
    ">- The weights are selected using a Gaussian distribution, and each pixel is subjected to a weighted average that considers the pixels surrounding it.   \n",
    ">- By reducing high-frequency elements and improving overall image quality, this blurring technique creates softer, more visually pleasant images.  \n",
    "4. Canny Edge Detector: \n",
    ">- It computes gradient in all directions of our blurred image and traces the edges with large changes in intensity.   \n",
    "5. Region of Interest: \n",
    ">- This step is to take into account only the region covered by the road lane.  \n",
    ">- A mask is created here, which is of the same dimension as our road image.   \n",
    ">- Furthermore, bitwise AND operation is performed between each pixel of our canny image and this mask.   \n",
    ">- It ultimately masks the canny image and shows the region of interest traced by the polygonal contour of the mask.\n",
    "6. Hough Line Transform: \n",
    ">- In image processing, the Hough transformation is a feature extraction method used to find basic geometric objects like lines and circles.   \n",
    ">- By converting the picture space into a parameter space, it makes it possible to identify shapes by accumulating voting points.   \n",
    ">- We'll use the probabilistic Hough Line Transform in our algorithm.   \n",
    ">- The Hough transformation has been extended to address the computational complexity with the probabilistic Hough transformation.   \n",
    ">- In order to speed up processing while preserving accuracy in shape detection, it randomly chooses a selection of picture points and applies the Hough transformation solely to those points.\n",
    "7. Draw lines on the Image or Video:  \n",
    ">- After identifying lane lines in our field of interest using Hough Line Transform, we overlay them on our visual input(video stream/image).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "def process_video(test_video, output_video):\n",
    "    \"\"\"\n",
    "    Read input video stream and produce a video file with detected lane lines.\n",
    "    Parameters:\n",
    "        test_video: location of input video file\n",
    "        output_video: location where output video file is to be saved  \n",
    "    \"\"\"\n",
    "    input_video = editor.VideoFileClip(test_video, audio=False)  # read the video file using VideoFileClip without audio\n",
    "    processed = input_video.fl_image(frame_processor)\n",
    "    processed.write_videofile(output_video, audio=False)   # save the output video stream to an mp4 file\n",
    "\n",
    "def frame_processor(image):\n",
    "    \"\"\"\n",
    "    Process the input frame to detect lane lines.\n",
    "    Parameters:\n",
    "        image: image of a road where one wants to detect lane lines\n",
    "        (we will be passing frames of video to this function)\n",
    "    \"\"\"\n",
    "    grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    kernel_size = 5\n",
    "    blur = cv2.GaussianBlur(grayscale, (kernel_size, kernel_size), 0)\n",
    "    low_t = 50                             # first threshold for the hysteresis procedure\n",
    "    high_t = 150                           # second threshold for the hysteresis procedure \n",
    "    edges = cv2.Canny(blur, low_t, high_t) # applying canny edge detection and save edges in a variable\n",
    "    region = region_selection(edges)       # since we are getting too many edges from our image, we apply a mask polygon to only focus on the road\n",
    "    hough = hough_transform(region)        # Applying hough transform \n",
    "    result = draw_lane_lines(image, lane_lines(image, hough))  # draw the lines\n",
    "    return result\n",
    "\n",
    "def region_selection(image):\n",
    "    \"\"\"\n",
    "    Determine and cut the region of interest in the input image.\n",
    "    Parameters:\n",
    "        image: we pass here the output from canny where we have \n",
    "        identified edges in the frame\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = np.zeros_like(image)    # create an array of the same size as of the input image \n",
    "    \n",
    "    if len(image.shape) > 2:       # if you pass an image with more then one channel\n",
    "        channel_count = image.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:                          # this image only has one channel \n",
    "        ignore_mask_color = 255    # color of the mask polygon (white)\n",
    "    \n",
    "    rows, cols = image.shape[:2]              # creating a polygon to focus only on the road in the picture\n",
    "    bottom_left  = [cols * 0.1, rows * 0.95]  # create polygon (in accordance to how the camera was placed)\n",
    "    top_left     = [cols * 0.4, rows * 0.6]\n",
    "    bottom_right = [cols * 0.9, rows * 0.95]\n",
    "    top_right    = [cols * 0.6, rows * 0.6]\n",
    "    vertices = np.array([[bottom_left, top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)  # filling the polygon with white color and generating the final mask\n",
    "    masked_image = cv2.bitwise_and(image, mask)   # Bitwise AND on the input image and mask to get only the edges on the road\n",
    "    return masked_image  \n",
    "\n",
    "def hough_transform(image):\n",
    "    \"\"\"\n",
    "    Determine and cut the region of interest in the input image.\n",
    "    Parameter:\n",
    "        image: grayscale image which should be an output from the edge detector\n",
    "    \"\"\"\n",
    "    rho = 1              # Distance resolution of the accumulator in pixels                    \n",
    "    theta = np.pi/180    # Angle resolution of the accumulator in radians.\n",
    "    threshold = 20       # Only lines that are greater than threshold will be returned.\n",
    "    minLineLength = 20   # Line segments shorter than that are rejected.\n",
    "    maxLineGap = 500     # Maximum allowed gap between points on the same line to link them  \n",
    "    \n",
    "    return cv2.HoughLinesP(image, rho = rho, theta = theta, threshold = threshold, minLineLength = minLineLength, maxLineGap = maxLineGap)\n",
    "                         # returns an array containing dimensions of straight lines \n",
    "\n",
    "def average_slope_intercept(lines):\n",
    "    \"\"\"\n",
    "    Find the slope and intercept of the left and right lanes of each image.\n",
    "    Parameters:\n",
    "        lines: output from Hough Transform\n",
    "    \"\"\"\n",
    "    left_lines    = []              #(slope, intercept)\n",
    "    left_weights  = []              #(length,)\n",
    "    right_lines   = []              #(slope, intercept)\n",
    "    right_weights = []              #(length,)\n",
    "     \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            if x1 == x2:\n",
    "                continue\n",
    "            slope = (y2 - y1) / (x2 - x1)     # calculating slope of a line\n",
    "            intercept = y1 - (slope * x1)     # calculating intercept of a line\n",
    "            length = np.sqrt(((y2 - y1) ** 2) + ((x2 - x1) ** 2))  # calculating length of a line\n",
    "            \n",
    "            if slope < 0:     # slope of left lane is negative and for right lane slope is positive\n",
    "                left_lines.append((slope, intercept))\n",
    "                left_weights.append((length))\n",
    "            else:\n",
    "                right_lines.append((slope, intercept))\n",
    "                right_weights.append((length))\n",
    "                \n",
    "    left_lane  = np.dot(left_weights,  left_lines) / np.sum(left_weights)  if len(left_weights) > 0 else None\n",
    "    right_lane = np.dot(right_weights, right_lines) / np.sum(right_weights) if len(right_weights) > 0 else None\n",
    "    return left_lane, right_lane\n",
    "   \n",
    "def pixel_points(y1, y2, line):\n",
    "    \"\"\"\n",
    "    Converts the slope and intercept of each line into pixel points.\n",
    "        Parameters:\n",
    "            y1: y-value of the line's starting point.\n",
    "            y2: y-value of the line's end point.\n",
    "            line: The slope and intercept of the line.\n",
    "    \"\"\"\n",
    "    if line is None:\n",
    "        return None\n",
    "    slope, intercept = line\n",
    "    x1 = int((y1 - intercept)/slope)\n",
    "    x2 = int((y2 - intercept)/slope)\n",
    "    y1 = int(y1)\n",
    "    y2 = int(y2)\n",
    "    return ((x1, y1), (x2, y2))\n",
    "   \n",
    "def lane_lines(image, lines):\n",
    "    \"\"\"\n",
    "    Create full lenght lines from pixel points.\n",
    "        Parameters:\n",
    "            image: The input test image.\n",
    "            lines: The output lines from Hough Transform.\n",
    "    \"\"\"\n",
    "    left_lane, right_lane = average_slope_intercept(lines)\n",
    "    y1 = image.shape[0]\n",
    "    y2 = y1 * 0.6\n",
    "    left_line  = pixel_points(y1, y2, left_lane)\n",
    "    right_line = pixel_points(y1, y2, right_lane)\n",
    "    return left_line, right_line\n",
    " \n",
    "def draw_lane_lines(image, lines, color=[255, 0, 0], thickness=12):\n",
    "    \"\"\"\n",
    "    Draw lines onto the input image.\n",
    "        Parameters:\n",
    "            image: The input test image (video frame in our case).\n",
    "            lines: The output lines from Hough Transform.\n",
    "            color (Default = red): Line color.\n",
    "            thickness (Default = 12): Line thickness. \n",
    "    \"\"\"\n",
    "    line_image = np.zeros_like(image)\n",
    "    for line in lines:\n",
    "        if line is not None:\n",
    "            cv2.line(line_image, *line,  color, thickness)\n",
    "    return cv2.addWeighted(image, 1.0, line_image, 1.0, 0.0)\n",
    "\n",
    "cap = cv2.VideoCapture('./Videos/lane.mp4')  \n",
    "  \n",
    "while (1):  \n",
    "  \n",
    "    ret, frame = cap.read()  \n",
    "    cv2.imshow('Original', frame)  \n",
    "    result=frame_processor(frame)\n",
    "    cv2.imshow('Lanes', result)  \n",
    "  \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV-py36",
   "language": "python",
   "name": "cv_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
